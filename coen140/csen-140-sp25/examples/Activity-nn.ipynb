{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Classification\n",
    "\n",
    "The activity shows an example of designing and training a neural network model using TensorFlow.\n",
    "\n",
    "Reference: https://adventuresinmachinelearning.com/neural-networks-tutorial/, https://www.tensorflow.org/tutorials/quickstart/beginner, https://www.tensorflow.org/tutorials/quickstart/advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as r\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  4., 15., 12.,  0.,  0.,  0.,  0.,  3., 16., 15.,\n",
       "       14.,  0.,  0.,  0.,  0.,  8., 13.,  8., 16.,  0.,  0.,  0.,  0.,\n",
       "        1.,  6., 15., 11.,  0.,  0.,  0.,  1.,  8., 13., 15.,  1.,  0.,\n",
       "        0.,  0.,  9., 16., 16.,  5.,  0.,  0.,  0.,  0.,  3., 13., 16.,\n",
       "       16., 11.,  5.,  0.,  0.,  0.,  0.,  3., 11., 16.,  9.,  0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset, show data\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[2]) \n",
    "plt.show()\n",
    "digits.data[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.33501649, -0.04308102,  0.27407152, -0.66447751,\n",
       "       -0.84412939, -0.40972392, -0.12502292, -0.05907756, -0.62400926,\n",
       "        0.4829745 ,  0.75962245, -0.05842586,  1.12772113,  0.87958306,\n",
       "       -0.13043338, -0.04462507,  0.11144272,  0.89588044, -0.86066632,\n",
       "       -1.14964846,  0.51547187,  1.90596347, -0.11422184, -0.03337973,\n",
       "        0.48648928,  0.46988512, -1.49990136, -1.61406277,  0.07639777,\n",
       "        1.54181413, -0.04723238,  0.        ,  0.76465553,  0.05263019,\n",
       "       -1.44763006, -1.73666443,  0.04361588,  1.43955804,  0.        ,\n",
       "       -0.06134367,  0.8105536 ,  0.63011714, -1.12245711, -1.06623158,\n",
       "        0.66096475,  0.81845076, -0.08874162, -0.03543326,  0.74211893,\n",
       "        1.15065212, -0.86867056,  0.11012973,  0.53761116, -0.75743581,\n",
       "       -0.20978513, -0.02359646, -0.29908135,  0.08671869,  0.20829258,\n",
       "       -0.36677122, -1.14664746, -0.5056698 , -0.19600752])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale data\n",
    "X_scale = StandardScaler()\n",
    "X = X_scale.fit_transform(digits.data)\n",
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train/test\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(8), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert output to binary (1-hot encoding) vector\n",
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect\n",
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)\n",
    "y_train[0], y_v_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the neural network\n",
    "nn_structure = [64, 30, 10]\n",
    "def f(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def f_deriv(x):\n",
    "    return f(x) * (1 - f(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent algorithm works as follows:\n",
    "\n",
    "Randomly initialise the weights for each layer $W^{(l)}$.  \n",
    "While iterations < iteration limit:  \n",
    "1. Set $\\Delta W$ and $\\Delta b$ to zero.  \n",
    "2. For samples 1 to m:  \n",
    "   a. Perform a feed foward pass through all the $n_l$ layers. Store the activation function outputs $h^{(l)}$.  \n",
    "   b. Calculate the $\\delta^{(n_l)}$ value for the output layer.  \n",
    "   c. Use backpropagation to calculate the $\\delta^{(l)}$ values for layers 2 to $n_l-1$.  \n",
    "   d. Update the $\\Delta W^{(l)}$ and $\\Delta b^{(l)}$  for each layer.  \n",
    "3. Perform a gradient descent step using:  \n",
    "$W^{(l)} = W^{(l)}-\\alpha[\\frac{1}{m}\\Delta W^{(l)}]$,  \n",
    "$b^{(l)} = b^{(l)}-\\alpha[\\frac{1}{m}\\Delta b^{(l)}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters to random values\n",
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {}\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1]))\n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b\n",
    "\n",
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b\n",
    "\n",
    "def feed_forward(x, W, b):\n",
    "    h = {1: x}\n",
    "    z = {}\n",
    "    for l in range(1, len(W) + 1):\n",
    "        # if it is the first layer, then the input into the weights is x, otherwise, \n",
    "        # it is the output from the last layer\n",
    "        if l == 1:\n",
    "            node_in = x\n",
    "        else:\n",
    "            node_in = h[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l] # z^(l+1) = W^(l)*h^(l) + b^(l)  \n",
    "        h[l+1] = f(z[l+1]) # h^(l) = f(z^(l)) \n",
    "    return h, z\n",
    "\n",
    "def calculate_out_layer_delta(y, h_out, z_out):\n",
    "    # delta^(nl) = -(y_i - h_i^(nl)) * f'(z_i^(nl))\n",
    "    return -(y-h_out) * f_deriv(z_out)\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    # delta^(l) = (transpose(W^(l)) * delta^(l+1)) * f'(z^(l))\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)\n",
    "\n",
    "def train_nn(nn_structure, X, y, iter_num=3000, alpha=0.25):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    m = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(len(y)):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored h and z values, to be used in the\n",
    "            # gradient descent step\n",
    "            h, z = feed_forward(X[i, :], W, b)\n",
    "            # loop from nl-1 to 1 backpropagating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], h[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-h[l]))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    # triW^(l) = triW^(l) + delta^(l+1) * transpose(h^(l))\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(h[l][:,np.newaxis])) \n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/m * tri_W[l])\n",
    "            b[l] += -alpha * (1.0/m * tri_b[l])\n",
    "        # complete the average cost calculation\n",
    "        avg_cost = 1.0/m * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 3000 iterations\n",
      "Iteration 0 of 3000\n",
      "Iteration 1000 of 3000\n",
      "Iteration 2000 of 3000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 12.1 ms, total: 1min 32s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model and plot cost function\n",
    "W, b, avg_cost_func = train_nn(nn_structure, X_train, y_v_train)\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.26425591098747"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assess model performance\n",
    "def predict_y(W, b, X, n_layers):\n",
    "    m = X.shape[0]\n",
    "    y = np.zeros((m,))\n",
    "    for i in range(m):\n",
    "        h, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(h[n_layers])\n",
    "    return y\n",
    "\n",
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow beginner version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 21:47:02.006931: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-21 21:47:02.007543: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-21 21:47:02.010610: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-21 21:47:02.017025: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747889222.030118 1203122 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747889222.033683 1203122 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747889222.043364 1203122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747889222.043382 1203122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747889222.043383 1203122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747889222.043384 1203122 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-21 21:47:02.046792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/342wi25/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-05-21 21:47:04.447642: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.42605343, -0.64465978, -0.83632464,  0.07362774,  0.01733539,\n",
       "         0.0057504 , -0.43591   ,  0.22595035,  0.80904107,  0.19142091]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if necessary, install tensorflow\n",
    "# !python -m pip install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# load and split dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Stack the layers\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# For each example the model returns a vector of \"logits\" or \"log-odds\" scores, one for each class.\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13988804, 0.04794858, 0.03958556, 0.09833861, 0.09295582,\n",
       "        0.09188514, 0.0590792 , 0.11451883, 0.20516818, 0.11063205]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tf.nn.softmax function converts these logits to \"probabilities\" for each class\n",
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.3872159354885283)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The losses.SparseCategoricalCrossentropy loss takes a vector of logits and a True index and returns a scalar loss for each example.\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m  74/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5093 - loss: 1.6067   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 21:47:25.631345: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:25.632447: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:25.632476: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:25.650502: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:25.650614: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:25.650639: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8581 - loss: 0.4858\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1553\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9686 - loss: 0.1053\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9729 - loss: 0.0891\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0737\n",
      "CPU times: user 53.7 s, sys: 7.41 s, total: 1min 1s\n",
      "Wall time: 14.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70315a58b740>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# compile and fit/learn the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 21:47:41.707101: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:41.707177: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:41.707211: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:41.717094: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:41.717165: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:47:41.717191: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - 1ms/step - accuracy: 0.9742 - loss: 0.0776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07758945741069108, 0.9742]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each example the model returns a vector of \"logits\" or \"log-odds\" scores, one for each class.\n",
    "predictions = model(x_train[:1]).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Load and prepare the MNIST dataset.\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Add a channels dimension\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "# Use tf.data to batch and shuffle the dataset:\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
    "\n",
    "# Build the tf.keras model using the Keras model subclassing API\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = Conv2D(32, 3, activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.d1 = Dense(128, activation='relu')\n",
    "        self.d2 = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()\n",
    "\n",
    "# Choose an optimizer and loss function for training\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Select metrics to measure the loss and the accuracy of the model.\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "# Use tf.GradientTape to train the model\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(images, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "# test the model\n",
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 21:51:10.070871: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.071078: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.071110: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.071286: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.071331: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.089379: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.089539: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.089565: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.089711: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:10.089736: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.484153: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-05-21 21:51:48.573510: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.573768: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.573814: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.574053: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.574095: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.583133: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.583613: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.583689: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.584027: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:48.584085: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.770213: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.770507: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.770557: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.770846: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.770895: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.780890: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.781168: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.781226: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.781526: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.781576: W tensorflow/core/util/util.cc:163] Not handling type DT_DOUBLE\n",
      "2025-05-21 21:51:50.795044: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.13633119985822476, Accuracy: 95.93333333333334, Test Loss: 0.06351376654585165, Test Accuracy: 97.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 21:52:33.705856: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.04301686567680312, Accuracy: 98.69166666666666, Test Loss: 0.056993261542554595, Test Accuracy: 98.11\n",
      "Epoch 3, Loss: 0.02198059282152498, Accuracy: 99.285, Test Loss: 0.055321268759557105, Test Accuracy: 98.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 21:54:00.630433: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.015034607285751216, Accuracy: 99.50833333333333, Test Loss: 0.05853091319092901, Test Accuracy: 98.36\n",
      "Epoch 5, Loss: 0.009202098545492707, Accuracy: 99.69666666666667, Test Loss: 0.060265470648025954, Test Accuracy: 98.34\n",
      "CPU times: user 42min 21s, sys: 57.7 s, total: 43min 19s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# do the actual training\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Reset the metrics at the start of the next epoch\n",
    "    train_loss.reset_state()\n",
    "    train_accuracy.reset_state()\n",
    "    test_loss.reset_state()\n",
    "    test_accuracy.reset_state()\n",
    "\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3728999514738719, Accuracy: 89.59333333333333, Test Loss: 0.17383548468351365, Test Accuracy: 94.76\n",
      "Epoch 2, Loss: 0.17461996620893477, Accuracy: 95.04166666666667, Test Loss: 0.12125341929495334, Test Accuracy: 96.61\n",
      "Epoch 3, Loss: 0.12820954078038532, Accuracy: 96.22833333333334, Test Loss: 0.09911573641002178, Test Accuracy: 97.13\n",
      "Epoch 4, Loss: 0.10220954126020272, Accuracy: 96.89333333333333, Test Loss: 0.08685830254107714, Test Accuracy: 97.34\n",
      "Epoch 5, Loss: 0.0874946305056413, Accuracy: 97.35833333333333, Test Loss: 0.0789394410327077, Test Accuracy: 97.67\n",
      "Training time: 23.18 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Define the model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training and evaluation loop\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_accuracy = 100.0 * correct / total\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "\n",
    "    test_loss /= test_total\n",
    "    test_accuracy = 100.0 * test_correct / test_total\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {train_loss}, Accuracy: {train_accuracy}, \"\n",
    "          f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Training time: {end - start:.2f} seconds\")\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mnist_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1203122/2838543760.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('mnist_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0789394410327077, Test Accuracy: 97.67\n"
     ]
    }
   ],
   "source": [
    "# At a later time, you can load the model and evaluate it\n",
    "\n",
    "# Load the model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('mnist_model.pth'))\n",
    "model.eval()\n",
    "# Test the model\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "test_loss /= test_total\n",
    "test_accuracy = 100.0 * test_correct / test_total\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "342wi25",
   "language": "python",
   "name": "342wi25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
